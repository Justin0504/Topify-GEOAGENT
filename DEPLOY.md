# Open WebUI éƒ¨ç½²åˆ° Web å¹³å°æŒ‡å—

## ğŸš€ éƒ¨ç½²æ–¹æ¡ˆ

### æ–¹æ¡ˆ 1: Docker éƒ¨ç½²ï¼ˆæ¨èï¼‰

è¿™æ˜¯æœ€ç®€å•å’Œå¯é çš„éƒ¨ç½²æ–¹å¼ï¼Œé€‚åˆå¤§å¤šæ•°äº‘å¹³å°ã€‚

#### 1.1 æ„å»º Docker é•œåƒ

```bash
# åœ¨é¡¹ç›®æ ¹ç›®å½•æ‰§è¡Œ
docker build -t open-webui:latest .
```

#### 1.2 è¿è¡Œå®¹å™¨

```bash
docker run -d \
  -p 8080:8080 \
  -v open-webui-data:/app/backend/data \
  -e WEBUI_SECRET_KEY=$(openssl rand -base64 32) \
  -e OLLAMA_BASE_URL=http://your-ollama-server:11434 \
  --name open-webui \
  --restart unless-stopped \
  open-webui:latest
```

### æ–¹æ¡ˆ 2: ç›´æ¥ Python éƒ¨ç½²

é€‚åˆå·²æœ‰ Python ç¯å¢ƒçš„æœåŠ¡å™¨ã€‚

#### 2.1 ç”Ÿäº§ç¯å¢ƒå®‰è£…

```bash
# 1. åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python3.12 -m venv venv
source venv/bin/activate

# 2. å®‰è£…ä¾èµ–
pip install -r backend/requirements.txt

# 3. æ„å»ºå‰ç«¯
npm install --legacy-peer-deps --engine-strict=false
npm run build

# 4. å®‰è£…é¡¹ç›®
pip install -e .
```

#### 2.2 ä½¿ç”¨ Gunicorn è¿è¡Œï¼ˆç”Ÿäº§ç¯å¢ƒæ¨èï¼‰

```bash
# å®‰è£… gunicorn
pip install gunicorn

# è¿è¡Œï¼ˆå¤šè¿›ç¨‹ï¼Œé€‚åˆç”Ÿäº§ç¯å¢ƒï¼‰
gunicorn open_webui.main:app \
  --workers 4 \
  --worker-class uvicorn.workers.UvicornWorker \
  --bind 0.0.0.0:8080 \
  --timeout 120 \
  --access-logfile - \
  --error-logfile -
```

### æ–¹æ¡ˆ 3: ä½¿ç”¨ Systemd æœåŠ¡ï¼ˆLinux æœåŠ¡å™¨ï¼‰

åˆ›å»º systemd æœåŠ¡æ–‡ä»¶ï¼Œå®ç°è‡ªåŠ¨å¯åŠ¨å’Œç®¡ç†ã€‚

## ğŸ“‹ éƒ¨ç½²åˆ° topify.ai æˆ–å…¶ä»–å¹³å°çš„æ­¥éª¤

### æ­¥éª¤ 1: å‡†å¤‡éƒ¨ç½²æ–‡ä»¶

1. **æ„å»ºå‰ç«¯**
   ```bash
   npm run build
   ```

2. **å‡†å¤‡ç¯å¢ƒå˜é‡**
   åˆ›å»º `.env` æ–‡ä»¶ï¼š
   ```env
   WEBUI_SECRET_KEY=your-secret-key-here
   OLLAMA_BASE_URL=http://your-ollama-server:11434
   OPENAI_API_KEY=your-openai-key-if-needed
   PORT=8080
   HOST=0.0.0.0
   ```

### æ­¥éª¤ 2: é…ç½®åå‘ä»£ç†ï¼ˆNginxï¼‰

å¦‚æœä½¿ç”¨è‡ªå·±çš„æœåŠ¡å™¨ï¼Œéœ€è¦é…ç½® Nginxï¼š

```nginx
server {
    listen 80;
    server_name topify.ai www.topify.ai;

    # é‡å®šå‘åˆ° HTTPS
    return 301 https://$server_name$request_uri;
}

server {
    listen 443 ssl http2;
    server_name topify.ai www.topify.ai;

    ssl_certificate /path/to/ssl/cert.pem;
    ssl_certificate_key /path/to/ssl/key.pem;

    # å¢åŠ ä¸Šä¼ æ–‡ä»¶å¤§å°é™åˆ¶
    client_max_body_size 100M;

    location / {
        proxy_pass http://localhost:8080;
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "upgrade";
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        proxy_read_timeout 86400;
    }

    # WebSocket æ”¯æŒ
    location /ws {
        proxy_pass http://localhost:8080;
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "upgrade";
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
    }
}
```

### æ­¥éª¤ 3: é…ç½® SSL è¯ä¹¦

ä½¿ç”¨ Let's Encrypt å…è´¹è¯ä¹¦ï¼š

```bash
# å®‰è£… certbot
sudo apt-get install certbot python3-certbot-nginx

# è·å–è¯ä¹¦
sudo certbot --nginx -d topify.ai -d www.topify.ai
```

### æ­¥éª¤ 4: é…ç½®é˜²ç«å¢™

```bash
# å…è®¸ HTTP å’Œ HTTPS
sudo ufw allow 80/tcp
sudo ufw allow 443/tcp
```

## ğŸ”§ ç¯å¢ƒå˜é‡é…ç½®

### å¿…éœ€çš„ç¯å¢ƒå˜é‡

- `WEBUI_SECRET_KEY`: ç”¨äºåŠ å¯†çš„å¯†é’¥ï¼ˆè‡ªåŠ¨ç”Ÿæˆæˆ–æ‰‹åŠ¨è®¾ç½®ï¼‰
- `PORT`: æœåŠ¡ç«¯å£ï¼ˆé»˜è®¤ 8080ï¼‰

### å¯é€‰çš„ç¯å¢ƒå˜é‡

```env
# Ollama é…ç½®
OLLAMA_BASE_URL=http://localhost:11434

# OpenAI é…ç½®
OPENAI_API_KEY=sk-...
OPENAI_API_BASE_URL=https://api.openai.com/v1

# æ•°æ®åº“é…ç½®
DATABASE_URL=sqlite:///./data/webui.db
# æˆ– PostgreSQL
# DATABASE_URL=postgresql://user:password@localhost:5432/webui

# Redis é…ç½®ï¼ˆç”¨äºä¼šè¯ç®¡ç†ï¼‰
REDIS_URL=redis://localhost:6379

# CORS é…ç½®
CORS_ALLOW_ORIGIN=https://topify.ai,https://www.topify.ai

# æ—¥å¿—çº§åˆ«
GLOBAL_LOG_LEVEL=INFO

# å…¶ä»–é…ç½®
WEBUI_URL=https://topify.ai
ENABLE_SIGNUP=false  # ç¦ç”¨æ³¨å†Œ
ENABLE_LOGIN=true    # å¯ç”¨ç™»å½•
```

## ğŸ“¦ å¹³å°ç‰¹å®šéƒ¨ç½²

### Vercel / Netlify

è¿™äº›å¹³å°ä¸»è¦æ”¯æŒé™æ€ç½‘ç«™ï¼ŒOpen WebUI éœ€è¦åç«¯ APIï¼Œå»ºè®®ï¼š

1. å‰ç«¯éƒ¨ç½²åˆ° Vercel/Netlify
2. åç«¯ API éƒ¨ç½²åˆ°å…¶ä»–å¹³å°ï¼ˆå¦‚ Railway, Render, Fly.ioï¼‰

### Railway / Render / Fly.io

è¿™äº›å¹³å°æ”¯æŒ Docker å’Œ Python åº”ç”¨ï¼š

1. **Railway**: ç›´æ¥è¿æ¥ GitHubï¼Œè‡ªåŠ¨éƒ¨ç½² Docker å®¹å™¨
2. **Render**: æ”¯æŒ Dockerfile æˆ–ç›´æ¥è¿è¡Œ Python
3. **Fly.io**: æ”¯æŒ Docker éƒ¨ç½²ï¼Œå…¨çƒè¾¹ç¼˜ç½‘ç»œ

### AWS / GCP / Azure

ä½¿ç”¨äº‘å¹³å°çš„å®¹å™¨æœåŠ¡ï¼š

- **AWS**: ECS, EKS, App Runner
- **GCP**: Cloud Run, GKE
- **Azure**: Container Instances, AKS

## ğŸ›¡ï¸ å®‰å…¨å»ºè®®

1. **ä½¿ç”¨ HTTPS**: å¿…é¡»é…ç½® SSL è¯ä¹¦
2. **è®¾ç½®å¼ºå¯†é’¥**: `WEBUI_SECRET_KEY` ä½¿ç”¨å¼ºéšæœºå­—ç¬¦ä¸²
3. **é™åˆ¶è®¿é—®**: ä½¿ç”¨é˜²ç«å¢™é™åˆ¶ IP è®¿é—®
4. **å®šæœŸæ›´æ–°**: ä¿æŒ Docker é•œåƒå’Œä¾èµ–æ›´æ–°
5. **å¤‡ä»½æ•°æ®**: å®šæœŸå¤‡ä»½ `/app/backend/data` ç›®å½•

## ğŸ“Š ç›‘æ§å’Œæ—¥å¿—

### å¥åº·æ£€æŸ¥

```bash
# æ£€æŸ¥æœåŠ¡çŠ¶æ€
curl http://localhost:8080/health

# åº”è¯¥è¿”å›: {"status":true}
```

### æŸ¥çœ‹æ—¥å¿—

```bash
# Docker æ—¥å¿—
docker logs -f open-webui

# Systemd æ—¥å¿—
journalctl -u open-webui -f
```

## ğŸ”„ æ›´æ–°éƒ¨ç½²

```bash
# 1. æ‹‰å–æœ€æ–°ä»£ç 
git pull

# 2. é‡æ–°æ„å»º
docker build -t open-webui:latest .

# 3. åœæ­¢æ—§å®¹å™¨
docker stop open-webui
docker rm open-webui

# 4. å¯åŠ¨æ–°å®¹å™¨ï¼ˆä½¿ç”¨ç›¸åŒçš„æ•°æ®å·ï¼‰
docker run -d \
  -p 8080:8080 \
  -v open-webui-data:/app/backend/data \
  --name open-webui \
  open-webui:latest
```

## ğŸ“ å¸¸è§é—®é¢˜

### Q: å¦‚ä½•é…ç½®è‡ªå®šä¹‰åŸŸåï¼Ÿ

A: åœ¨ DNS æä¾›å•†å¤„æ·»åŠ  A è®°å½•ï¼ŒæŒ‡å‘æœåŠ¡å™¨ IPï¼Œç„¶åé…ç½® Nginxã€‚

### Q: å¦‚ä½•å¯ç”¨ç”¨æˆ·æ³¨å†Œï¼Ÿ

A: è®¾ç½®ç¯å¢ƒå˜é‡ `ENABLE_SIGNUP=true`

### Q: å¦‚ä½•è¿æ¥è¿œç¨‹ Ollama æœåŠ¡å™¨ï¼Ÿ

A: è®¾ç½® `OLLAMA_BASE_URL=http://your-ollama-server:11434`

### Q: å¦‚ä½•å¤‡ä»½æ•°æ®ï¼Ÿ

A: å¤‡ä»½ Docker å·ï¼š`docker run --rm -v open-webui-data:/data -v $(pwd):/backup alpine tar czf /backup/backup.tar.gz /data`

## ğŸ¯ å¿«é€Ÿéƒ¨ç½²è„šæœ¬

æŸ¥çœ‹ `deploy.sh` è„šæœ¬è·å–ä¸€é”®éƒ¨ç½²æ–¹æ¡ˆã€‚


